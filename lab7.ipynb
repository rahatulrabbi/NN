{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "317ae474-b0d6-4798-a24c-87aaa2857940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8695f601-322c-4ff4-86e2-a2bfbdc5a0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.2983711063861847\n",
      "Epoch 1000, Loss: 0.0002707050589378923\n",
      "Epoch 2000, Loss: 9.042368037626147e-05\n",
      "Epoch 3000, Loss: 4.388535307953134e-05\n",
      "Epoch 4000, Loss: 2.489008147676941e-05\n",
      "Epoch 5000, Loss: 1.5388504834845662e-05\n",
      "Epoch 6000, Loss: 1.0049888260255102e-05\n",
      "Epoch 7000, Loss: 6.816366294515319e-06\n",
      "Epoch 8000, Loss: 4.752399945573416e-06\n",
      "Epoch 9000, Loss: 3.3828823688963894e-06\n",
      "Epoch 10000, Loss: 2.4476007638440933e-06\n",
      "Epoch 11000, Loss: 1.7939109966391698e-06\n",
      "Epoch 12000, Loss: 1.3286518196764519e-06\n",
      "Epoch 13000, Loss: 9.925176982505945e-07\n",
      "Epoch 14000, Loss: 7.467624527635053e-07\n",
      "\n",
      "Final weights and biases:\n",
      "hidden.weight: tensor([[0.1833, 0.2667],\n",
      "        [0.2826, 0.3652]])\n",
      "hidden.bias: tensor([1.0170, 1.0025])\n",
      "output.weight: tensor([[-1.4728, -1.4261],\n",
      "        [ 1.5441,  1.5950]])\n",
      "output.bias: tensor([-2.3714,  2.1961])\n",
      "\n",
      "Final output (y1, y2): 0.01, 0.99\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# To Avoid Issues Use This Link \n",
    "# https://colab.research.google.com/drive/1u8B2-TPpHR8UBMhi2LumBpqKOw_yxdIu?usp=sharing\n",
    "\n",
    "# Define the neural network class\n",
    "class SimpleANN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleANN, self).__init__()\n",
    "        # Input to Hidden layer (2 inputs to 2 hidden nodes)\n",
    "        self.hidden = nn.Linear(2, 2)  # 2 input neurons, 2 hidden neurons\n",
    "        # Hidden to Output layer (2 hidden nodes to 2 output nodes)\n",
    "        self.output = nn.Linear(2, 2)  # 2 hidden neurons, 2 output neurons\n",
    "        # Sigmoid activation function\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Forward pass through the network\n",
    "        h = self.sigmoid(self.hidden(x))  # Hidden layer activation\n",
    "        y = self.sigmoid(self.output(h))  # Output layer activation\n",
    "        return y\n",
    "\n",
    "# Create the network\n",
    "model = SimpleANN()\n",
    "\n",
    "# Set the weights and biases based on the diagram\n",
    "with torch.no_grad():\n",
    "    model.hidden.weight = torch.nn.Parameter(torch.tensor([[0.15, 0.20], [0.25, 0.30]]))  # w1, w2, w3, w4\n",
    "    model.hidden.bias = torch.nn.Parameter(torch.tensor([0.35, 0.35]))  # Bias b1 for both hidden neurons\n",
    "    model.output.weight = torch.nn.Parameter(torch.tensor([[0.40, 0.45], [0.50, 0.55]]))  # w5, w6, w7, w8\n",
    "    model.output.bias = torch.nn.Parameter(torch.tensor([0.60, 0.60]))  # Bias b2 for both output neurons\n",
    "\n",
    "# Define input (x1, x2) and target values (T1, T2)\n",
    "inputs = torch.tensor([[0.05, 0.10]])  # Single input pair\n",
    "targets = torch.tensor([[0.01, 0.99]])  # Target values for y1 and y2\n",
    "\n",
    "# Define the loss function (Mean Squared Error Loss)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Define the optimizer (Stochastic Gradient Descent)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.5)\n",
    "\n",
    "# Number of epochs (iterations)\n",
    "epochs = 15000\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass: Compute predicted output by passing inputs to the model\n",
    "    output = model(inputs)\n",
    "    \n",
    "    # Compute the loss (Mean Squared Error)\n",
    "    loss = criterion(output, targets)\n",
    "    \n",
    "    # Zero gradients, perform a backward pass, and update the weights\n",
    "    optimizer.zero_grad()  # Clear the gradients from the previous step\n",
    "    loss.backward()  # Backpropagation step\n",
    "    optimizer.step()  # Update weights\n",
    "\n",
    "    # Print the loss every 1000 epochs\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
    "\n",
    "# Print final weights and biases after training\n",
    "print(\"\\nFinal weights and biases:\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.data}\")\n",
    "\n",
    "# Final output after training\n",
    "final_output = model(inputs)\n",
    "print(f\"\\nFinal output (y1, y2): {final_output[0][0]:.2f}, {final_output[0][1]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dd6baf-5668-41c8-b750-6fc82e383593",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
